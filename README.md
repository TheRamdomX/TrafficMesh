# ğŸš¦ TrafficMesh - Plataforma Distribuida para Monitoreo de TrÃ¡fico en Tiempo Real

Plataforma distribuida para la recolecciÃ³n, procesamiento y anÃ¡lisis en tiempo real de datos de trÃ¡fico urbano de la RegiÃ³n Metropolitana de Chile, utilizando fuentes pÃºblicas como Waze Live Map.

[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/TheRamdomX/TrafficMesh)
[![Docker](https://img.shields.io/badge/Docker-Containers-blue)](https://www.docker.com/)
[![Kafka](https://img.shields.io/badge/Kafka-Streaming-orange)](https://kafka.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.9%2B-green)](https://www.python.org/)
[![Selenium](https://img.shields.io/badge/Selenium-WebDriver-brightgreen)](https://www.selenium.dev/documentation/webdriver/)
[![MySQL](https://img.shields.io/badge/MySQL-8.0-lightgrey)](https://www.mysql.com/)
[![Redis](https://img.shields.io/badge/Redis-Cache-red)](https://redis.io/)
[![Apache Pig](https://img.shields.io/badge/Apache-Pig-orange)](https://pig.apache.org/)
[![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.11-yellow)](https://www.elastic.co/)
[![Kibana](https://img.shields.io/badge/Kibana-Visualization-purple)](https://www.elastic.co/kibana)

---

## ï¿½ Tabla de Contenidos

- [DescripciÃ³n General](#-descripciÃ³n-general)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [Parte 1: RecolecciÃ³n y Almacenamiento](#-parte-1-sistema-de-recolecciÃ³n-y-almacenamiento)
- [Parte 2: Procesamiento y AnÃ¡lisis](#-parte-2-sistema-de-procesamiento-y-anÃ¡lisis)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Quick Start](#-quick-start)
- [Estructura del Proyecto](#-estructura-del-proyecto)

---

## ğŸ¯ DescripciÃ³n General

**TrafficMesh** es un sistema completo de Big Data que combina:

- **Streaming en tiempo real** con Kafka y Redis
- **Procesamiento batch** con Apache Pig
- **Almacenamiento persistente** en MySQL y Elasticsearch
- **VisualizaciÃ³n de datos** con Kibana
- **SimulaciÃ³n de cargas** para pruebas de rendimiento de cachÃ©

### Tipos de Eventos Detectados

| Tipo | DescripciÃ³n |
|------|-------------|
| ğŸš§ CAMINO CORTADO | VÃ­as bloqueadas o cerradas |
| âš ï¸ PELIGRO | Condiciones peligrosas en la vÃ­a |
| ğŸ‘® POLICIA | Controles o presencia policial |
| ğŸ’¥ ACCIDENTE | Colisiones vehiculares |
| ğŸš— CONGESTION | TrÃ¡fico lento o atascado |

---

## ğŸ— Arquitectura del Sistema

### Flujo de Datos Completo

```mermaid
graph TB
    subgraph "RecolecciÃ³n en Tiempo Real"
        W[ğŸŒ Waze Live Map] --> S[ğŸ§  Scraper]
        S -->|eventos| K[(ğŸ“¨ Kafka)]
        K -->|consume| ST[ğŸ“¦ Storage]
        ST --> M[(ğŸ—„ï¸ MySQL)]
    end
    
    subgraph "SimulaciÃ³n de TrÃ¡fico"
        M --> TG[ğŸ¯ Traffic Generator]
        TG -->|consultas| K
        K --> CS[ğŸ§Š Cache System]
        CS --> R[(âš¡ Redis)]
    end
    
    subgraph "Procesamiento Batch"
        M -->|export| F[ğŸ” Pig Filter]
        F -->|filtrado| P[ğŸ· Pig Processor]
        P -->|anÃ¡lisis| EI[ğŸ“Š Elastic Inserter]
        EI --> ES[(ğŸ” Elasticsearch)]
    end
    
    subgraph "VisualizaciÃ³n"
        ES --> KB[ğŸ“ˆ Kibana]
        ES --> EC[ğŸ§Š Elastic-Cache]
        EC --> R
    end
```

---

## ğŸ“¦ Parte 1: Sistema de RecolecciÃ³n y Almacenamiento

### Componentes

| Componente | DescripciÃ³n | Funcionamiento |
|------------|-------------|----------------|
| ğŸ§  **Scraper** | Web scraping de Waze | Divide la RM en 2025 cuadrantes (45x45), usa 15 threads con Selenium para extraer eventos, identifica comunas con GeoJSON |
| ğŸ“¦ **Storage** | Persistencia de eventos | Consume de Kafka y almacena en MySQL (timestamp, lat, lon, tipo, comuna) |
| ğŸ¯ **Traffic Generator** | Simulador de consultas | Genera consultas con distribuciÃ³n uniforme y logarÃ­tmica (Zipf) para testing de cachÃ© |
| ğŸ§Š **Cache System** | Sistema de cachÃ© dual | Implementa polÃ­ticas LRU y Random con Redis como backend |

### Diagrama de Arquitectura

```mermaid
graph LR
    A[ğŸ§  Scraper] -->|produce| B[(ğŸ“¨ Kafka)]
    B -->|consume| C[ğŸ“¦ Storage]
    C --> D[(ğŸ—„ï¸ MySQL)]
    D --> E[ğŸ¯ Traffic Generator]
    E -->|queries| B
    B --> F[ğŸ§Š Cache System]
    F --> G[(âš¡ Redis)]
    F -.->|miss| D
```

### Servicios - Parte 1

| ğŸŒ Servicio          | ğŸ”¢ Puerto | ğŸ“ DescripciÃ³n              |
|---------------------|-----------|------------------------------|
| ğŸ§­ Zookeeper         | 2181      | CoordinaciÃ³n de Kafka        |
| ğŸ’¬ Kafka             | 9092      | Broker de mensajes           |
| ğŸ—„ï¸ MySQL             | 3306      | Base de datos relacional     |
| âš¡ Redis             | 6379      | Sistema de cachÃ© distribuido |
| ğŸ§  Scraper           | -         | ExtracciÃ³n de datos de Waze  |
| ğŸ“¦ Storage           | -         | Almacenamiento de eventos    |
| ğŸ¯ Traffic Generator | -         | Generador de consultas       |
| ğŸ§Š Cache System      | -         | Cache con polÃ­ticas hÃ­bridas |

---

## ğŸ“¦ Parte 2: Sistema de Procesamiento y AnÃ¡lisis

### Componentes

| Componente | DescripciÃ³n | Funcionamiento |
|------------|-------------|----------------|
| ğŸ” **Pig Filter** | EliminaciÃ³n de duplicados | Detecta eventos duplicados por proximidad (<11m) y tiempo (<5min) usando Apache Pig |
| ğŸ· **Pig Processor** | AnÃ¡lisis estadÃ­stico | Genera anÃ¡lisis por comuna, tipo de evento y distribuciÃ³n horaria |
| ğŸ“Š **Elastic Inserter** | Carga a Elasticsearch | Convierte resultados de Pig y los indexa con mappings geoespaciales |
| ğŸ§Š **Elastic-Cache** | Cache con Elasticsearch | Sistema de cachÃ© que usa Elasticsearch como fuente de datos |

### Diagrama de Arquitectura

```mermaid
graph LR
    A[(ğŸ—„ï¸ MySQL)] -->|export CSV| B[ğŸ” Pig Filter]
    B -->|eventos Ãºnicos| C[ğŸ· Pig Processor]
    C -->|anÃ¡lisis| D[ğŸ“Š Elastic Inserter]
    D --> E[(ğŸ” Elasticsearch)]
    E --> F[ğŸ“ˆ Kibana]
    E --> G[ğŸ§Š Elastic-Cache]
    G --> H[(âš¡ Redis)]
```

### Servicios - Parte 2

| ğŸŒ Servicio | ğŸ”¢ Puerto | ğŸ“ DescripciÃ³n |
|-------------|-----------|----------------|
| ğŸ” Elasticsearch | 9200 | Motor de bÃºsqueda y anÃ¡lisis |
| ğŸ“ˆ Kibana | 5601 | VisualizaciÃ³n de datos |
| ğŸ” Pig Filter | - | Filtrado de duplicados con Apache Pig |
| ğŸ· Pig Processor | - | Procesamiento y anÃ¡lisis de eventos |
| ï¿½ Elastic Inserter | - | Carga de datos a Elasticsearch |
| ğŸ§Š Elastic-Cache | - | Cache con backend Elasticsearch |

### AnÃ¡lisis Generados

#### 1. ğŸ“ AnÃ¡lisis por Comuna
- Total de eventos por comuna
- Cantidad de tipos distintos de eventos
- Desglose detallado por tipo y comuna

#### 2. â° AnÃ¡lisis Temporal
- DistribuciÃ³n de eventos por hora del dÃ­a (0-23h)
- Patrones temporales por tipo de evento
- IdentificaciÃ³n de horas pico

#### 3. ğŸ”„ Filtrado de Duplicados
- EliminaciÃ³n de eventos a menos de ~11 metros
- Filtrado de eventos en ventana de 5 minutos
- ReducciÃ³n de redundancia en los datos

---

## ğŸ›  TecnologÃ­as

| CategorÃ­a | TecnologÃ­a | Uso |
|-----------|------------|-----|
| **MensajerÃ­a** | Apache Kafka | Streaming de eventos entre componentes |
| **CoordinaciÃ³n** | Zookeeper | GestiÃ³n de cluster Kafka |
| **Web Scraping** | Selenium + Chrome | ExtracciÃ³n de datos de Waze |
| **Base de Datos** | MySQL 8.0 | Almacenamiento persistente |
| **CachÃ©** | Redis | Cache de alto rendimiento |
| **Procesamiento** | Apache Pig | ETL y anÃ¡lisis batch |
| **BÃºsqueda** | Elasticsearch 8.11 | IndexaciÃ³n y bÃºsqueda de eventos |
| **VisualizaciÃ³n** | Kibana 8.11 | Dashboards y exploraciÃ³n de datos |
| **Geoespacial** | GeoPandas + Shapely | IdentificaciÃ³n de comunas |
| **Contenedores** | Docker Compose | OrquestaciÃ³n de servicios |

---

## ğŸš€ Quick Start

```bash
# Clonar el repositorio
git clone https://github.com/TheRamdomX/TrafficMesh.git
cd TrafficMesh

# Levantar todos los servicios
docker-compose up --build

# O en modo detached
docker-compose up -d --build
```

### Acceso a Servicios

| Servicio | URL |
|----------|-----|
| Kibana | http://localhost:5601 |
| Elasticsearch | http://localhost:9200 |
| MySQL | localhost:3306 |
| Redis | localhost:6379 |

---

## ğŸ“ Estructura del Proyecto

```
TrafficMesh/
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # OrquestaciÃ³n de servicios
â”œâ”€â”€ ğŸ“„ README.md               # DocumentaciÃ³n
â”‚
â”œâ”€â”€ ğŸ§  Scraper/                # Web scraping de Waze
â”‚   â”œâ”€â”€ scraper.py             # Script principal (15 threads)
â”‚   â”œâ”€â”€ RM.geojson             # PolÃ­gonos de comunas RM
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“¦ Storage/                # Persistencia en MySQL
â”‚   â”œâ”€â”€ storage.py             # Consumidor Kafka â†’ MySQL
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ¯ Trafic/                 # Generador de consultas
â”‚   â”œâ”€â”€ traffic_generator.py   # Distribuciones uniforme/log
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ§Š Cache/                  # Sistema de cachÃ© (Kafka)
â”‚   â”œâ”€â”€ cache_system.py        # LRU + Random + Redis
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ” Filter/                 # Filtrado de duplicados
â”‚   â”œâ”€â”€ filter_events.pig      # Script Apache Pig
â”‚   â”œâ”€â”€ init.sh                # Export MySQL â†’ CSV
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ· Pig/                    # Procesamiento y anÃ¡lisis
â”‚   â”œâ”€â”€ process_events.pig     # AnÃ¡lisis comuna/hora
â”‚   â”œâ”€â”€ export_events.sh       # PreparaciÃ³n de datos
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“Š Elastic/                # InserciÃ³n a Elasticsearch
â”‚   â”œâ”€â”€ Insert.py              # Carga de datos e Ã­ndices
â”‚   â””â”€â”€ Dockerfile
â”‚
â””â”€â”€ ğŸ§Š Elastic-Cache/          # Cache con Elasticsearch
    â”œâ”€â”€ cache_system.py        # LRU + Random + ES
    â””â”€â”€ Dockerfile
```

